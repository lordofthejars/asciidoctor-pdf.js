== Reactive Programming

Quarkus implements https://github.com/eclipse/microprofile-reactive-streams-operators[MicroProfile Reactive spec, window="_blank"] and uses RXJava2 to provide reactive programming model.

[source, bash]
----
./mvnw quarkus:add-extension 
  -Dextensions="
    io.quarkus:quarkus-smallrye-reactive-streams-operators"
----

Asynchronous HTTP endpoint is implemented by returning Java `CompletionStage`.
You can create this class either manually or using MicroProfile Reactive Streams spec:

[source, java]
----
@GET
@Path("/reactive")
@Produces(MediaType.TEXT_PLAIN)
public CompletionStage<String> getHello() {
    return ReactiveStreams.of("h", "e", "l", "l", "o")
    .map(String::toUpperCase)
    .toList()
    .run()
    .thenApply(list -> list.toString());
}
----

Creating streams is also easy, you just need to return `Publisher` object.

[source, java]
----
@GET
@Path("/stream")
@Produces(MediaType.SERVER_SENT_EVENTS)
public Publisher<String> publishers() {
        return Flowable
        .interval(500, TimeUnit.MILLISECONDS)
        .map(s -> atomicInteger.getAndIncrement())
        .map(i -> Integer.toString(i));
}
----

== Reactive Messaging
// tag::update_1_4[]
Quarkus relies on MicroProfile https://github.com/eclipse/microprofile-reactive-messaging[Reactive Messaging spec, window="_blank"] to implement reactive messaging streams.

[source, bash]
----
mvn quarkus:add-extension 
    -Dextensions="
        io.quarkus:quarkus-smallrye-reactive-messaging"
----

You can just start using in-memory streams by using `@Incoming` to produce data and `@Outgoing` to consume data.

Produce every 5 seconds one piece of data.

[source, java]
----
@ApplicationScoped
public class ProducerData {

    @Outgoing("my-in-memory")
    public Flowable<Integer> generate() {
        return Flowable.interval(5, TimeUnit.SECONDS)
                .map(tick -> random.nextInt(100));
    }
}
----

If you want to dispatch to all subscribers you can annotate the method with `@Broadcast`.

Consumes generated data from `my-in-memory` stream.

[source, java]
----
@ApplicationScoped
public class ConsumerData {
    @Incoming("my-in-memory")
    public void randomNumber(int randomNumber) {
        System.out.println("Received " + randomNumber);
    }
}
----

You can also inject an stream as a field:

[source, java]
----
@Inject
@Stream("my-in-memory") Publisher<Integer> randomRumbers;
----

// tag::update_3_8[]

[source, java]
----
@Inject @Stream("generated-price")
Emitter<String> emitter;
----

*Patterns*

_REST API -> Message_

[source, java]
----
@Inject @Stream(“in”)
Emitter<String> emitter;

emitter.send(message);
----

_Message -> Message_

[source, java]
----
@Incoming(“in”)
@Outgoing(“out”)
public String process(String in) {
}
----

_Message -> SSE_

[source, java]
----
@Inject @Stream(“out”)
Publisher<String> result;

@GET
@Produces(SERVER_SENT_EVENTS)
public Publisher<String> stream() {
    return result;
}
----

_Message -> Business Logic_

[source, java]
----
@ApplicationScoped
public class ReceiverMessages {
    @Incoming("prices")
    public void print(String price) {
    }
}
----

Possible implementations are:

*In-Memory*

If the stream is not configured then it is assumed to be an in-memory stream, if not then stream type is defined by `connector` field.

*Kafka*

To integrate with Kafka you need to add next extensions:

[source, bash]
----
mvn quarkus:add-extension 
    -Dextensions="
    io.quarkus:quarkus-smallrye-reactive-messaging-kafka"
----

Then `@Outgoing`, `@Incoming` or `@Stream` can be used.

Kafka configuration schema: `mp.messaging.[outgoing|incoming].\{stream-name\}.<property>=<value>`.

The `connector` type is `smallrye-kafka`.

[source, properties]
----
mp.messaging.outgoing.generated-price.connector=
    smallrye-kafka
mp.messaging.outgoing.generated-price.topic=
    prices
mp.messaging.outgoing.generated-price.bootstrap.servers=
    localhost:9092
mp.messaging.outgoing.generated-price.value.serializer=
    org.apache.kafka.common.serialization.IntegerSerializer

mp.messaging.incoming.prices.connector=
    smallrye-kafka
mp.messaging.incoming.prices.value.deserializer=
    org.apache.kafka.common.serialization.IntegerDeserializer
----

A complete list of supported properties are in Kafka site. For the https://kafka.apache.org/documentation/#producerconfigs[producer, window="_blank"] and for https://kafka.apache.org/documentation/#consumerconfigs[consumer, window="_blank"]

_JSON-B Serializer/Deserializer_

You can use JSON-B to serialize/deserialize objects.

[source, bash]
----
./mvnw quarkus:add-extension 
    -Dextensions="quarkus-kafka-client"
----

To serialize you can use `io.quarkus.kafka.client.serialization.JsonbSerializer`.

To deserialize you need to extend `io.quarkus.kafka.client.serialization.JsonbDeserializer` and provide a type.

[source, java]
----
public class BeerDeserializer 
    extends JsonbDeserializer<Beer> {

    public BeerDeserializer() {
        super(Beer.class);
    }

}
----

*AMQP*

To integrate with AMQP you need to add next extensions:

[source, bash]
----
./mvnw quarkus:add-extension 
    -Dextensions="reactive-messaging-amqp"
----

Then `@Outgoing`, `@Incoming` or `@Stream` can be used.

AMQP configuration schema: `mp.messaging.[outgoing|incoming].\{stream-name\}.<property>=<value>`.
Special properties `amqp-username` and `amqp-password` are used to configure AMQP broker credentials.

The connector type is `smallrye-amqp`.

[source, properties]
----
amqp-username=quarkus
amqp-password=quarkus
# write
mp.messaging.outgoing.generated-price.connector=
    smallrye-amqp
mp.messaging.outgoing.generated-price.address=
    prices
mp.messaging.outgoing.generated-price.durable=
    true
# read
mp.messaging.incoming.prices.connector=
    smallrye-amqp
mp.messaging.incoming.prices.durable=
    true
----

A complete list of supported properties for https://smallrye.io/smallrye-reactive-messaging/#_interacting_using_amqp[AMQP, window="_blank"].

*MQTT*

To integrate with MQTT you need to add next extensions:

[source, bash]
----
./mvnw quarkus:add-extension 
    -Dextensions="vertx, smallrye-reactive-streams-operators
        smallrye-reactive-messaging"
----

And add `io.smallrye.reactive:smallrye-reactive-messaging-mqtt-1.0:0.0.10` dependency in your build tool.

Then `@Outgoing`, `@Incoming` or `@Stream` can be used.

MQTT configuration schema: `mp.messaging.[outgoing|incoming].\{stream-name\}.<property>=<value>`.

The connector type is `smallrye-mqtt`.

[source, properties]
----
mp.messaging.outgoing.topic-price.type=
    smallrye-mqtt
mp.messaging.outgoing.topic-price.topic=
    prices
mp.messaging.outgoing.topic-price.host=
    localhost
mp.messaging.outgoing.topic-price.port=
    1883
mp.messaging.outgoing.topic-price.auto-generated-client-id=
    true

mp.messaging.incoming.prices.type=
    smallrye-mqtt
mp.messaging.incoming.prices.topic=
    prices
mp.messaging.incoming.prices.host=
    localhost
mp.messaging.incoming.prices.port=
    1883
mp.messaging.incoming.prices.auto-generated-client-id=
    true
----
// end::update_3_8[]
// end::update_1_4[]

== Kafka Streams
// tag::update_3_10[]
Create streaming queries with the Kafka Streams API.

[source, bash]
----
./mvnw quarkus:add-extension 
  -Dextensions="kafka-streams"
----

You need to initialize `org.apache.kafka.streams.KafkaStreams` on startup:

[source, java]
----
private KafkaStreams streams;

void onStart(@Observes StartupEvent ev) {
    Properties props = new Properties();
    // ...
    StreamsBuilder builder = new StreamsBuilder();
    // ...
    streams = new KafkaStreams(builder.build(), props);

    executor = Executors.newSingleThreadExecutor();
    executor.execute(() -> {
        waitForTopicsToBeCreated(bootstrapServers);
        streams.start();
    });
}

void onStop(@Observes ShutdownEvent ev) {
    streams.close();
    executor.shutdown();
}
----

And then you can use it.

[source, java]
----
public List getData() {
    return streams.allMetadataForStore("")
                .stream()
                .map()
                .collect()
}

----
// end::update_3_10[]

== Reactive PostgreSQL Client
// tag::update_1_8[]
You can use Reactive PostgreSQL to execute queries to PostreSQL database in a reactive way, instead of using JDBC way.

[source, bash]
----
./mvnw quarkus:add-extension 
  -Dextensions="io.quarkus:quarkus-reactive-pg-client"
----

Database configuration is the same as shown in <<Persistence>> section, but URL is different as it is not a _jdbc_.

[source, properties]
----
quarkus.datasource.url=
    vertx-reactive:postgresql://host:5431/db
----

Then you can inject `io.reactiverse.axle.pgclient.PgPool` class.

[source, java]
----
@Inject
PgPool client;

CompletionStage<JsonArray> = 
    client.query("SELECT * FROM table")  
    .thenApply(pgRowSet -> {
        JsonArray jsonArray = new JsonArray();
        PgIterator iterator = pgRowSet.iterator();
        return jsonArray;
    })
----
// end::update_1_8[]
