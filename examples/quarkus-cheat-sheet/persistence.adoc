== Persistence

Quarkus works with JPA(Hibernate) as persistence solution.
But also provides an https://en.wikipedia.org/wiki/Active_record_pattern[Active Record pattern] implementation under Panache project.

To use database access you need to add Quarkus JDBC drivers instead of the original ones.
At this time `H2`, `MariaDB`, `MSSQL` and `PostgreSQL` drivers are supported.

[source, bash]
----
./mvnw quarkus:add-extension 
  -Dextensions="io.quarkus:quarkus-hibernate-orm-panache, 
                io.quarkus:quarkus-jdbc-mariadb"
----

[source, java]
----
@Entity
public class Developer extends PanacheEntity {

    // id field is implicit

    public String name;
}
----

And configuration in `src/main/resources/application.properties`:

[source, properties]
----
quarkus.datasource.url=jdbc:mariadb://localhost:3306/mydb
quarkus.datasource.driver=org.mariadb.jdbc.Driver
quarkus.datasource.username=developer
quarkus.datasource.password=developer
quarkus.hibernate-orm.database.generation=update
----

Database operations:

[source, java]
----
// Insert
Developer developer = new Developer();
developer.name = "Alex";
developer.persist();

// Find All
Developer.findAll().list();

// Find By Query
Developer.find("name", "Alex").firstResult();

// Delete
Developer developer = new Developer();
developer.id = 1;
developer.delete();

// Delete By Query
long numberOfDeleted = Developer.delete("name", "Alex");
----

<<<

Remember to annotate methods with `@Transactional` annotation to make changes persisted in the database.

If queries start with the keyword `from` then they are treated as _HQL_ query, if not then next short form is supported:

* `order by` which expands to `from EntityName order by ...`
* `<columnName>` which expands to `from EntityName where <columnName>=?`
* `<query>` which is expanded to `from EntityName where <query>`

*Static Methods*

|===	
| Field | Parameters | Return

a| `findById`
a| `Object`
a| Returns object or null if not found.

a| `find`
a| `String`, [`Object...`, `Map<String, Object>`, `Parameters`]
a| Lists of entities meeting given query with parameters set.

a| `find`
a| `String`, `Sort`, [`Object...`, `Map<String, Object>`, `Parameters`]
a| Lists of entities meeting given query with parameters set sorted by `Sort` attribute/s.

a| `findAll`
a| 
a| Finds all entities.

a| `findAll`
a| `Sort`
a| Finds all entities sorted by `Sort` attribute/s.

a| `stream`
a| `String`, [`Object...`, `Map<String, Object>`, `Parameters`]
a| `java.util.stream.Stream` of entities meeting given query with parameters set.

a| `stream`
a| `String`, `Sort`, [`Object...`, `Map<String, Object>`, `Parameters`]
a| `java.util.stream.Stream` of entities meeting given query with parameters set sorted by `Sort` attribute/s.

a| `streamAll`
a| 
a| `java.util.stream.Stream` of all entities.

a| `streamAll`
a| `Sort`
a| `java.util.stream.Stream` of all entities sorted by `Sort` attribute/s.

a| `count`
a| 
a| `Number of entities.

a| `count`
a| `String`, [`Object...`, `Map<String, Object>`, `Parameters`]
a| Number of entities meeting given query with parameters set.

a| `deleteAll`
a| 
a| Number of deleted entities.

a| `delete`
a| `String`, [`Object...`, `Map<String, Object>`, `Parameters`]
a| Number of deleted entities meeting given query with parameters set.

a| `persist`
a| [`Iterable`, `Steram`, `Object...`]
a| 
|===

// tag::update_2_10[]
If entities are defined in external JAR, you need to enable in these projects the `Jandex` plugin in project.

[source, xml]
----
<plugin>
    <groupId>org.jboss.jandex</groupId>
    <artifactId>jandex-maven-plugin</artifactId>
    <version>1.0.3</version>
    <executions>
        <execution>
            <id>make-index</id>
            <goals>
                <goal>jandex</goal>
            </goals>
        </execution>
    </executions>
    <dependencies>
        <dependency>
            <groupId>org.jboss</groupId>
            <artifactId>jandex</artifactId>
            <version>2.1.1.Final</version>
        </dependency>
    </dependencies>
</plugin>
----
// end::update_2_10[]

*DAO pattern*

// tag::update_2_12[]
Panache also supports _DAO_ pattern by providing `PanacheRepository<TYPE>` interface.

[source, java]
----
@ApplicationScoped
public class DeveloperRepository 
    implements PanacheRepository<Person> {
   public Person findByName(String name){
     return find("name", name).firstResult();
   }
}
----
// end::update_2_12[]

// tag::update_4_4[]
*Flushing*

You can force flush operation by calling `.flush()` or `.persistAndFlush()` to make it in a single call.

IMPORTANT: This flush is less efficient and you still need to commit transaction.
// end::update_4_4[]

// tag::update_4_3[]
*Testing*

There is a Quarkus Test Resource that starts and stops H2 server before and after test suite.

Register next dependency `io.quarkus:quarkus-test-h2:test`.

And annotate the test:

[source, java]
----
@QuarkusTestResource(H2DatabaseTestResource.class)
public class FlywayTestResources {
}
----
// end::update_4_3[]

== Flyway
// tag::update_1_7[]
Quarkus integrates with https://flywaydb.org/[Flyway] to help you on database schema migrations.

[source, bash]
----
./mvnw quarkus:add-extension 
  -Dextensions="io.quarkus:quarkus-flyway"
----

Then place migration files to the migrations folder (`classpath:db/migration`).

You can inject `org.flywaydb.core.Flyway` to programmatically execute the migration.

[source, java]
----
@Inject
Flyway flyway;

flyway.migrate();
----

Or can be automatically executed by setting `migrate-at-start` property to `true`.

[source, properties]
----
quarkus.flyway.migrate-at-start=true
----

List of Flyway parameters.

`quarkus.` as prefix is skipped in the next table.

|===	
|Parameter | Default | Description

a|`flyway.migrate-at-start`
a|`false`
|Flyway migration automatically.

a|`flyway.locations`
a|`classpath:db/migration`
|CSV locations to scan recursively for migrations. Supported prefixes `classpath` and `filesystem`.

a|`flyway.connect-retries`
a|0
|The maximum number of retries when attempting to connect.

a|`flyway.schemas`
a|none
|CSV case-sensitive list of schemas managed.

a|`flyway.table`
a|`flyway_schema_history`
|The name of Flyway’s schema history table.

a|`flyway.sql-migration-prefix`
a|`V`
|Prefix for versioned SQL migrations. 

a|`flyway.repeatable-sql-migration-prefix`
a|`R`
|Prefix for repeatable SQL migrations.
|===
// end::update_1_7[]

== Hibernate Search
// tag::update_3_1[]

Quarkus integrates with https://www.elastic.co/products/elasticsearch[Elasticsearch] to provide a full-featured full-text search using https://hibernate.org/search/[Hibernate Search] API. 

[source, bash]
----
./mvnw quarkus:add-extension 
  -Dextensions="quarkus-hibernate-search-elasticsearch"
----

You need to annotate your model with Hibernate Search API to index it:

[source, java]
----
@Entity
@Indexed
public class Author extends PanacheEntity {

    @FullTextField(analyzer = "english")
    public String bio;

    @FullTextField(analyzer = "name")
    @KeywordField(name = "firstName_sort", 
        sortable = Sortable.YES, 
        normalizer = "sort")
    public String firstName;

    @OneToMany
    @IndexedEmbedded
    public List<Book> books;

}
----

IMPORTANT: It is not mandatory to use Panache.

You need to define the analyzers and normalizers defined in annotations.
You only need to implement `ElasticsearchAnalysisConfigurer` interface and configure it.

[source, java]
----
public class MyQuarkusAnalysisConfigurer 
            implements ElasticsearchAnalysisConfigurer {

    @Override
    public void configure(
        ElasticsearchAnalysisDefinitionContainerContext ctx) 
    {
            ctx.analyzer("english").custom()
                .withTokenizer("standard")
                .withTokenFilters("asciifolding", 
                    "lowercase", "porter_stem");

        ctx.normalizer("sort").custom() 
            .withTokenFilters("asciifolding", "lowercase");
    }
}
----

Use Hibernate Search in REST service:

[source, java]
----
public class LibraryResource {

    @Inject
    EntityManager em;

    @Transactional
    public List<Author> searchAuthors(
        @QueryParam("pattern") String pattern) { 
        return Search.getSearchSession(em)
            .search(Author.class)
            .predicate(f ->
                pattern == null || pattern.isEmpty() ?
                    f.matchAll() :
                    f.simpleQueryString()
                        .onFields("firstName", 
                            "lastName", "books.title")
                        .matching(pattern)
                )
            .sort(f -> f.byField("lastName_sort")
            .then().byField("firstName_sort"))
            .fetchHits();
    }
----

*IMPORTANT* If you are importing data without using Hibernate ORM, you need to index data by using `Search.getSearchSession(em).createIndexer()` `.startAndWait()` at startup time.

You need to configure the extension in `application.properties`:

[source, properties]
----
quarkus.hibernate-search.elasticsearch.version=7
quarkus.hibernate-search.elasticsearch.
    analysis-configurer=MyQuarkusAnalysisConfigurer
quarkus.hibernate-search.elasticsearch.
    automatic-indexing.synchronization-strategy=searchable
quarkus.hibernate-search.elasticsearch.
    index-defaults.lifecycle.strategy=drop-and-create
quarkus.hibernate-search.elasticsearch.
    index-defaults.lifecycle.required-status=yellow
----

List of Hibernate-Elasticsearch properties prefixed with `quarkus.hibernate-search.elasticsearch`:

|===	
|Parameter | Description

a|`backends`
|Map of configuration of additional backends.

a|`version`
|Version of Elasticsearch

a|`analysis-configurer`
|Class or name of the neab used to configure.

a|`hosts`
|List of Elasticsearch servers hosts.

a|`username`
|Username for auth.

a|`password`
|Password for auth.

a|`connection-timeout`
|Duration of connection timeout.

a|`max-connections`
|Max number of connections to servers.

a|`max-connections-per-route`
|Max number of connections to server.

a|`indexes`
|Per-index specific configuration.

a|`discovery.enabled`
|Enables automatic discovery.

a|`discovery.refresh-interval`
|Refresh interval of node list.

a|`discovery.default-scheme`
|Scheme to be used for the new nodes.

a|`automatic-indexing.synchronization-strategy`
a|Status for which you wait before considering the operation completed (`queued`,`committed` or `searchable`).

a|`automatic-indexing.enable-dirty-check`
|When enabled, re-indexing of is skipped if the changes are on properties that are not used when indexing. 

a|`index-defaults.lifecycle.strategy`
a|Index lifecycle (`none`, `validate`, `update`, `create`, `drop-and-create`, `drop-abd-create-drop`)

a|`index-defaults.lifecycle.required-status`
a|Minimal cluster status (`green`, `yellow`, `red`)

a|`index-defaults.lifecycle.required-status-wait-timeout`
|Waiting time before failing the bootstrap.

a|`index-defaults.refresh-after-write`
|Set if index should be refreshed after writes.
|===

Possible annotations:

|===	
|Parameter | Description

a|`@Indexed`
|Register entity as full text index

a|`@FullTextField`
|Full text search. Need to set an analyzer to split tokens.

a|`@KeywordField`
|The string is kept as one single token but can be normalized.

a|`IndexedEmbedded`
|Include the Book fields into the Author index.

a|`@ContainerExtraction`
a|Sets how to extract a value from container, e.g from a `Map`.

a|`@DocumentId`
| Map an unusual entity identifier to a document identifier.

a|`@GenericField`
|Full text index for any supported type.

a|`@IdentifierBridgeRef`
a|Reference to the identifier bridge to use for a `@DocumentId`.

a|`@IndexingDependency`
|How a dependency of the indexing process to a property should affect automatic reindexing.

a|`@ObjectPath`
|

a|`@ScaledNumberField`
a| For `java.math.BigDecimal` or `java.math.BigInteger` that you need higher precision.
|===
// end::update_3_1[]